# 训练过程可视化工具

## Tebsorboard

### 安装Tebsorboard

在运行 TensorBoard 之前，需要在同一环境中安装了 TensorFlow 和 TensorBoard。

在Anaconda Prompt窗口中输入

安装tensorflow

```
pip install tensorflow
```

安装tensorboard

```
pip install tensorboard
```

### 启动Tebsorboard

#### 激活相关环境

在Anaconda Prompt窗口中激活环境

```
conda activate 选择运行的环境环境
```

#### 启动 TensorBoard

在激活的环境中，运行以下命令

```
tensorboard --logdir=dir
```

这里dir是存储日志文件的目录

#### 访问 TensorBoard

在浏览器中输入 http://localhost:6006 来访问 TensorBoard 的界面

## 添加损失函数曲线

### add_scalar()函数

#### 解释

add_scalar()函数是PyTorch中用于将标量值添加到TensorBoard日志中的函数。

将指定的值添加到TensorBoard日志中，并将其与指定的标签相关联。

TensorBoard会将这些值绘制成曲线图，以便直观地观察训练过程中的变化趋势。

可以跟踪训练过程中的各种指标，例如损失值、准确率等，并将其可视化为曲线图。

#### 指定日志目录

```
# 需要先声明
log_dir = '自己设置'
writer = SummaryWriter(log_dir)
```

### 注意！！！

这里writer = SummaryWriter(log_dir)最好放在主进程中，以免有多进程存在从而造成多个日志产生。（由于这个已红温）

这里也可以使用当前时间戳创建日志目录

```
import time
log_dir = f'D:/ML/Task1/logs/{int(time.time())}'
```

在后面主块输出日志目录地址

```
print(f'Logging to: {log_dir}')
```

#### add_scalar()语法

```
add_scalar(tag, scalar_value, global_step=None)
```

tag：用于标识数据的标签名称，字符串类型。

scalar_value：要记录的标量值，可以是浮点数或字符串类型。Y轴。

global_step：全局步数，整数类型。如果未指定，则使用当前迭代的步数。X轴。

### eg1（简单使用）

#### 代码

```
from torch.utils.tensorboard import SummaryWriter
import numpy as np

# 指定日志目录
log_dir = 'D:\ML\Task2\log'			#自己设置的地址，需要提前在D:\ML\Task2下创造log文件夹
writer = SummaryWriter(log_dir)

# y = sin(x)
for i in range(100):
    writer.add_scalar("y=2x",np.sin(i),i)
    
# 训练结束后，关闭SummaryWriter
writer.close()
```

#### 输出

在根目录的logs文件夹中会保存tensorboard的事件

#### 启动TensorBoard可视化曲线

在对应虚拟环境终端输入下面命令，启动tensorboard

```
tensorboard --logdir='D:\ML\Task2\log' --port=6006
```

tensorboard 启动命令。

--logdir=logs 表示打开logs文件夹中的事件文件。

--port=6011 表示指定端口号，默认为6006，端口被占用时可以自定义其它端口号。比如改为port=6010

#### 测试（完整运行操作）

在 Anaconda Prompt 中输入来切换对应环境

```
conda activate pytorch
```

在相同的命令行窗口中运行模型

```
python TBtest.py
```

在新的命令行窗口中，启动 TensorBoard，指定日志目录和端口

```
tensorboard --logdir='D:\ML\Task2\log' --port=6006  #错误！
#这里再Windows终端导入路径需要用双引号或者不用引号，不能用单引号
tensorboard --logdir=D:\ML\Task2\log --port=6006  
tensorboard --logdir="D:\ML\Task2\log" --port=6006  
```

这里做了许多尝试都有问题，

<img src="https://raw.githubusercontent.com/Davereminisce/image/f5dddf88829d67bbf2fdacb365a4fd0b8a0cc265/%7BD09447FF-4942-44F4-95DC-730230EF591F%7D.png" alt="img" style="zoom:50%;" />

最后发现需要进行一些更改

##### 警告提示

<img src="https://raw.githubusercontent.com/Davereminisce/image/438c7099d5dd5b434ce360482d0bf1a7efe6c0d6/%7B3500E3A2-5E0D-471C-B2B6-F5131591A0BC%7D.png" alt="img" style="zoom:50%;" />

这里这些消息只是信息性警告，表示由于浮点数计算的顺序不同，可能会出现微小的数值差异。这通常不会影响您的程序运行或结果的有效性。

可以在模型前面带入以下代码来取消警告

```python
import os
os.environ["TF_ENABLE_ONEDNN_OPTS"] = "0"
```

##### Windows终端路径书写格式

在 Windows 命令行中，建议使用双引号（"）来包围路径，而不是单引号（'）。如果路径中没有空格，您也可以选择不加引号。下面是两种正确的写法：

1. 使用双引号：

   ```bash
   tensorboard --logdir="D:\ML\Task2\log" --port=6006
   ```

2. 如果路径没有空格，可以直接写：

   ```bash
   tensorboard --logdir=D:\ML\Task2\log --port=6006
   ```

##### 实时显示训练数据

不用等第一个窗口出结果就可以在第二个窗口启动TensorBoard

**启动模型**：在第一个命令行窗口中，运行您的模型代码

**同时启动 TensorBoard**：在另一个命令行窗口中，可以立即启动 TensorBoard

如果模型正在运行并且生成日志文件，TensorBoard 将能够实时读取这些更新并显示最新的训练状态。

##### 最终结果

<img src="https://raw.githubusercontent.com/Davereminisce/image/08d26573a154c99b7c60c9f0c1624236163aa820/%7B71058078-3A8A-436F-950C-3DD8595F6E68%7D.png" alt="img" style="zoom:50%;" />

### eg2（深度学习训练添加TensorBoard）

#### 函数添加位置

先导入tensorboard在代码开头部分

```python
from torch.utils.tensorboard import SummaryWriter
```

指定日志目录

```python
log_dir = '..\..\..'			
writer = SummaryWriter(log_dir)
```

找到主循环训练部分，添加add_scalar()函数在对应数据计算后的位置添加如Loss

```
loss = criterion(outputs, labels)
writer.add_scalar('loss/epoch', loss, epoch)
```

最后训练完成要关闭tensorboard

```
writer.close()
```

